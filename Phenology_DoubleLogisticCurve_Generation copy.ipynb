{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wheat Crop Phenology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "1. [Problem Statement](#Problem-Statement)\n",
    "2. [Dataset](#Dataset)\n",
    "    - [DAYMET](#DAYMET)\n",
    "    - [MODIS NDVI](#MODIS-NDVI)\n",
    "3. [MAIN FLOW](#MAIN-FLOW)\n",
    "4. [NDVI Smoothing](#NDVI-Smoothing)\n",
    "5. [Helper Functions](#Helper-Functions)\n",
    "    - [Two Peak Double Logistic fitting](#Two-Peak-Double-Logistic-fitting)\n",
    "    - [Double Logistic Loss](#Double-Logistic-Loss)\n",
    "    - [Dividing Index](#Dividing-Index)\n",
    "    - [Troughs and Crests](#Troughs-and-Crests)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Statement\n",
    "Given MODIS NDVI values and DAYMET temperature values, estimate the required crop growth metrics Day-of-Year (DOY) for wheat crop. The approach is to use a double logistic curve to fit the NDVI values and then use the fitted curve to estimate the phenological features. These features in addition to APTT values calculated from DAYMET temperature values are used to estimate the DOY values for crop growth metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import necessary modules, paths and variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from numpy.lib.function_base import diff\n",
    "import pandas as pd\n",
    "from scipy.optimize import least_squares\n",
    "from scipy import signal\n",
    "from scipy.special import expit\n",
    "import rasterio\n",
    "import matplotlib.pyplot as plt\n",
    "from unittest import result\n",
    "import rasterio\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### APTT Generation Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_aptt = True\n",
    "\n",
    "daymet_path = 'daymet_data'\n",
    "output_aptt_path = 'daymet_data/APTT_winterwheat'\n",
    "start_aptt_generation_year = 2020\n",
    "end_aptt_generation_year = 2021\n",
    "\n",
    "Tmin_Veg = 0.0\n",
    "Tmax_Veg = 35.0\n",
    "Topt_Veg = 24.0\n",
    "P_critical_Veg = 23.0\n",
    "P_optimum_Veg = 11.0\n",
    "\n",
    "Tmin_Rep = 8.0\n",
    "Tmax_Rep = 40.0\n",
    "Topt_Rep = 29.0\n",
    "P_critical_Rep = 18.0\n",
    "P_optimum_Rep = 12.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Double Logistic Curve Fitting Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndvi_path = 'NDVI_data'\n",
    "usda_path = 'USDA_data'\n",
    "\n",
    "# Minimum: 2009, Maximum: 2018\n",
    "ndvi_start_year = 2012\n",
    "ndvi_end_year = 2018\n",
    "\n",
    "if ndvi_start_year < 2009 or ndvi_end_year > 2018:\n",
    "    print('Error: ndvi_start_year must be greater than or equal to 2009 and ndvi_end_year must be less than or equal to 2018')\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### APTT Average Estimation Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aptt_start_year = 2020\n",
    "aptt_end_year = 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DAYMET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODIS NDVI\n",
    "\n",
    "There are two datasets used in this notebook. The first dataset is the MODIS NDVI values for the years 2000-2016. These are used to fit a double logistic curve.\n",
    "\n",
    "This data is the state-average calculated data. Let's load and plot the data.\n",
    "\n",
    "We want to filter in only dates from and to the 249th day of the year. This is because we want to fit the curve to the growing season only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(year):\n",
    "    state_avg_ndvi_year = pd.read_csv(os.path.join(ndvi_path, 'state_average_wheat_NDVI_'+str(year-1)+'_'+str(year)+'.csv'), usecols=['year', 'doy', 'NDVI'])\n",
    "\n",
    "    df = state_avg_ndvi_year[\n",
    "        ((state_avg_ndvi_year.year == year-1) & (state_avg_ndvi_year.doy >= 249)) | \n",
    "        ((state_avg_ndvi_year.year == year) & (state_avg_ndvi_year.doy <= 249))\n",
    "    ]\n",
    "\n",
    "    ndvi = np.array(df['NDVI']).astype(float)\n",
    "    doy = np.array(df['doy']+365*(df['year']-df.iloc[0]['year'])).astype(float)\n",
    "\n",
    "    # The overhead is doy[0], hence we subtact the overhead from doy\n",
    "    doy = doy - doy[0]\n",
    "\n",
    "    return ndvi, doy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in range(ndvi_start_year,ndvi_end_year):\n",
    "    ndvi, doy = get_data(year)\n",
    "\n",
    "    # Plot the NDVI\n",
    "    plt.figure(figsize=(3,1))\n",
    "    plt.plot(doy, ndvi, 'b-')\n",
    "    plt.xlabel('Day of Year')\n",
    "    plt.ylabel('NDVI')\n",
    "    plt.title('NDVI vs Day of Year for '+str(year-1)+'-'+str(year))\n",
    "    plt.show()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(APTT GENERATION HELPER FUNCTIONS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inialize Rasters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_rasters(tmin_path, tmax_path, dayl_path):\n",
    "    \n",
    "    raster1=rasterio.open(tmin_path)\n",
    "    tmin=raster1.read()\n",
    "    tmin=np.delete(tmin, list(range(181,365)), 0)\n",
    "\n",
    "    raster2=rasterio.open(tmax_path)\n",
    "    tmax=raster2.read()\n",
    "    tmax=np.delete(tmax, list(range(181,365)), 0)\n",
    "\n",
    "    t = (0.5*np.add(tmin,tmax))\n",
    "\n",
    "    raster3=rasterio.open(dayl_path)\n",
    "    dayl=raster3.read()/3600.0\n",
    "\n",
    "    return (tmin, tmax, t, dayl, raster1.height, raster1.width)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(DOUBLE LOGISTIC CURVE FITTING HELPER FUNCTIONS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Double Logistic Value\n",
    "This function returns the value of the double logistic curve at a given DOY value and the parameters for the double logistic curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_double_logistic_value(doy, params):\n",
    "    t = np.array(doy)\n",
    "    result = params[4] + (params[5]-params[4]) * (expit(params[0] * (t - params[1])) - expit(params[2] * (t - params[3])))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Double Logistic Loss\n",
    "The loss function is the sum of the differences between the actual ndvi and predicted double logistic ndvi values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def double_logistic_loss(params, ndvi, doy):\n",
    "    output = []\n",
    "    losses = ndvi - get_double_logistic_value(doy, params)\n",
    "    for loss in losses:\n",
    "        output.append(loss)\n",
    "    return np.array(output).squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Troughs and Crests\n",
    "Find the derivative of the fitted NDVI curve.\n",
    "Use scipy.signal.find_peaks to find the peaks and troughs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_troughs_and_crests(fitted_ndvi):\n",
    "    diffn = np.diff(fitted_ndvi)\n",
    "    crests, crest_values = signal.find_peaks(diffn, height=0)\n",
    "    troughs, trough_values = signal.find_peaks(-diffn, height=0)    \n",
    "    return troughs, crests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dividing Index\n",
    "Find the index where the fitted NDVI changes from the first peak to the second peak.\n",
    "Can be estimated as a function of troughs and crests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dividing_index(fitted_ndvi):\n",
    "    # troughs, crests = get_troughs_and_crests(fitted_ndvi)\n",
    "    # print('Trough:',troughs,'\\tCrest:',crests)\n",
    "    # # Figure out why\n",
    "    # if troughs[0] < crests[0] and len(troughs) > len(crests):\n",
    "    #     troughs = troughs[1:]\n",
    "\n",
    "    # if len(troughs)==2:\n",
    "    #     dividing_index = int(((2*troughs[0])+troughs[1])/3)\n",
    "    # elif len(crests)==2:\n",
    "    #     dividing_index = int((crests[0]+crests[1])/2)\n",
    "        \n",
    "    # The dividing index is the index of the first trough after the first crest\n",
    "    # return dividing_index\n",
    "    return 130"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Double Logistic fitting\n",
    "Identify if the curve is vegetative or reproductive.\n",
    "Use least square optimization to fit the curve using single peak double logistic loss.\n",
    "Make the Doys continuous and obtain the smooth fitted curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_ndvi(ndvi,doy,peak,end_doy):\n",
    "    if peak == 'vegetative':\n",
    "        init_params = [0.2, 50, 0.2, 100, 2500, 4500]\n",
    "        lower_bounds = [0.1, 25, 0.1, 75, 2000, 3800]\n",
    "        higher_bounds = [1, 75, 0.25, 150, 4000, 5500]\n",
    "    elif peak == 'reproductive':\n",
    "        init_params = [0.15, 160, 0.2, 275, 3500, 7000]\n",
    "        lower_bounds = [0.05, 50, 0.05, 150, 3000, 5500]\n",
    "        higher_bounds = [0.25, 250, 0.25, 350, 4000, 9000]\n",
    "    else:\n",
    "        raise Exception('Invalid peak type')\n",
    "\n",
    "    result = least_squares(\n",
    "        double_logistic_loss,\n",
    "        init_params,\n",
    "        bounds=(lower_bounds, higher_bounds),\n",
    "        max_nfev=100000,\n",
    "        args=(ndvi,doy)\n",
    "    )\n",
    "\n",
    "    xsol = result.x\n",
    "\n",
    "    doy = np.arange(doy[0], end_doy, 1)\n",
    "\n",
    "    fitted_ndvi = xsol[4] + (xsol[5]-xsol[4]) * (expit(xsol[0] * (doy - xsol[1])) - expit(xsol[2] * (doy - xsol[3])))\n",
    "\n",
    "    \n",
    "    return fitted_ndvi, doy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(ESTIMATING DOY VALUES FOR CROP GROWTH METRICS HELPER FUNCTIONS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract the Phenological Features\n",
    "This function uses the vegetation and reproductive ndvi and their derivates. It uses the troughs and crests on them to find the phenological features.\n",
    "\n",
    "<b>Vegetative Active Greenup</b> : Crest of the first derivative of the vegetative peak\n",
    "\n",
    "<b>Reproductive Active Greenup</b> : Crest of the first derivative of the reproductive peak\n",
    "\n",
    "<b>Reproductive Senescence</b> : Trough of the third derivative of the reproductive peak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_phenological_doy(vegetative_ndvi,reproductive_ndvi):\n",
    "    \n",
    "    vegetative_ndvi_diff1 = np.diff(vegetative_ndvi)\n",
    "    vegetative_ndvi_diff2 = np.diff(vegetative_ndvi_diff1)\n",
    "    vegetative_ndvi_diff3 = np.diff(vegetative_ndvi_diff2)\n",
    "    \n",
    "    vegetative_crests_diff1, _ = signal.find_peaks(vegetative_ndvi_diff1, height=0)\n",
    "    vegetative_greenup = int(vegetative_crests_diff1[0])\n",
    "    \n",
    "    reproductive_ndvi_diff1 = np.diff(reproductive_ndvi)\n",
    "    reproductive_ndvi_diff2 = np.diff(reproductive_ndvi_diff1)\n",
    "    reproductive_ndvi_diff3 = np.diff(reproductive_ndvi_diff2)\n",
    "    \n",
    "    reproductive_crests_diff1, _ = signal.find_peaks(reproductive_ndvi_diff1, height=0)\n",
    "    reproductive_greenup = int(reproductive_crests_diff1[0])\n",
    "\n",
    "    reproductive_troughs_diff1, _ = signal.find_peaks(-reproductive_ndvi_diff1, height=0)\n",
    "    reproductive_senescense = int(reproductive_troughs_diff1[0])\n",
    "\n",
    "    return {\n",
    "        'vegetative_ndvi_diff1': vegetative_ndvi_diff1, \n",
    "        'vegetative_ndvi_diff2': vegetative_ndvi_diff2,\n",
    "        'vegetative_ndvi_diff3': vegetative_ndvi_diff3,\n",
    "\n",
    "        'vegetative_greenup': vegetative_greenup,\n",
    "        \n",
    "        'reproductive_ndvi_diff1': reproductive_ndvi_diff1, \n",
    "        'reproductive_ndvi_diff2': reproductive_ndvi_diff2,\n",
    "        'reproductive_ndvi_diff3': reproductive_ndvi_diff3,\n",
    "\n",
    "        'reproductive_greenup': reproductive_greenup,\n",
    "        'reproductive_senescense': reproductive_senescense\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(PLOTTING HELPER FUNCTIONS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting values\n",
    "\n",
    "Use the global variables to plot the values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_number_of_years = ndvi_end_year - ndvi_start_year\n",
    "def plot_ndvi(x,y,title,data,discrete):\n",
    "    # plt.figure(figsize=(total_number_of_years*10,total_number_of_years*2))\n",
    "    plt.figure(figsize=(35,10))\n",
    "    plt.plot(x, y)\n",
    "    if discrete:\n",
    "        plt.plot(discrete[0], discrete[1], '--')\n",
    "    plt.xlabel('Day of Year')\n",
    "    plt.ylabel('NDVI')\n",
    "    plt.title(title)        \n",
    "\n",
    "    # Set markersize to 20 by default\n",
    "    plt.rcParams['lines.markersize'] = 15\n",
    "\n",
    "    # Set Marker border width to 2 by default\n",
    "    plt.rcParams['lines.markeredgecolor'] = 'black'\n",
    "    \n",
    "    for i, (vegetative_greenup, reproductive_greenup, reproductive_senescense, emergence, joint, heading, turning, ripening, harvesting)  in enumerate(data):\n",
    "        \n",
    "        plt.axvline(x.index(vegetative_greenup), color='green', linestyle='--', alpha=0.5)\n",
    "        plt.axvline(x.index(reproductive_greenup), color='green', linestyle='--', alpha=0.5)\n",
    "        plt.axvline(x.index(reproductive_senescense), color='red', linestyle='--', alpha=0.5)\n",
    "\n",
    "        plt.plot(emergence, y[x.index(emergence)], 'yo', alpha=0.9)\n",
    "        plt.plot(joint, y[x.index(joint)], 'co', alpha=0.9)\n",
    "        plt.plot(heading, y[x.index(heading)], 'mo', alpha=0.9)\n",
    "        plt.plot(turning, y[x.index(turning)], 'ko', alpha=0.9)\n",
    "        plt.plot(ripening, y[x.index(ripening)], 'bo', alpha=0.9)\n",
    "        plt.plot(harvesting, y[x.index(harvesting)], 'go', alpha=0.9)\n",
    "\n",
    "        \n",
    "    # Give labels to the points based on color\n",
    "    plt.plot([], [], 'yo', label='Emergence')\n",
    "    plt.plot([], [], 'co', label='Joint')\n",
    "    plt.plot([], [], 'mo', label='Heading')\n",
    "    plt.plot([], [], 'ko', label='Turning')\n",
    "    plt.plot([], [], 'bo', label='Ripening')\n",
    "    plt.plot([], [], 'go', label='Harvesting')\n",
    "\n",
    "    plt.xticks([x.index(249)], ['249'])\n",
    "    plt.xticks([i*365 for i in range(total_number_of_years+1)], [i+ndvi_start_year for i in range(total_number_of_years+1)])\n",
    "    \n",
    "    plt.legend(loc='upper left', bbox_to_anchor=(1, 1))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MAIN FLOW : APTT GENERATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alpha Values for the APTT calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_Veg = np.log(2)/np.log((Tmax_Veg-Tmin_Veg)/(Topt_Veg-Tmin_Veg))\n",
    "alpha_Rep = np.log(2)/np.log((Tmax_Rep-Tmin_Rep)/(Topt_Rep-Tmin_Rep))\n",
    "\n",
    "m = 3\n",
    "alpha_photo_Veg = np.log(2)/np.log((P_critical_Veg-P_optimum_Veg)/m + 1)\n",
    "alpha_photo_Rep = np.log(2)/np.log((P_critical_Rep-P_optimum_Rep)/m + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each year:\n",
    "1. Calculate the APTT values for the year using the DAYMET temperature values and the alpha values per pixel.\n",
    "2. Group the APTT values for the year for a given state into a raster. (Multiple areas are covered by a single state).\n",
    "\n",
    "Output is a raster for each year of dimensions ???.\n",
    "This raster is used to calculate the APTT values for the NDVI values.\n",
    "Output stored in the path: daymet_data/APTT_winterwheat/APTT_winterwheat_*_year.tif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_aptt_generation_year = 2019\n",
    "end_aptt_generation_year = 2020\n",
    "if generate_aptt:\n",
    "    # Supress invalid value warnings\n",
    "    np.seterr(invalid='ignore')\n",
    "    for year in tqdm(range(start_aptt_generation_year,end_aptt_generation_year)):\n",
    "\n",
    "        tmin_path = os.path.join(daymet_path, 'daymet_data_tmin', 'tmin_'+str(year)+'.tif')\n",
    "        tmax_path = os.path.join(daymet_path, 'daymet_data_tmax', 'tmax_'+str(year)+'.tif')\n",
    "        dayl_path = os.path.join(daymet_path, 'daymet_data_dayl', 'daylength_'+str(year)+'.tif')\n",
    "        \n",
    "        outfile_Veg = os.path.join(output_aptt_path, 'APTT_winterwheat_vegetative_phase_'+str(year)+'.tif')\n",
    "        outfile_Rep = os.path.join(output_aptt_path, 'APTT_winterwheat_reproductive_phase_'+str(year)+'.tif')\n",
    "\n",
    "        tmin, tmax, t, dayl, tot_rows, tot_cols = initialize_rasters(tmin_path, tmax_path, dayl_path)\n",
    "    \n",
    "        # Initialize the APTT arrays\n",
    "        ft1=np.copy(t)\n",
    "        ft1[t>=Tmax_Veg]=0\n",
    "        ft1[t<=Tmin_Veg]=0        \n",
    "        ft1[(t<Tmax_Veg) & (t>Tmin_Veg)]=((2 * (t-Tmin_Veg)**alpha_Veg * (Topt_Veg-Tmin_Veg)**alpha_Veg - (t-Tmin_Veg)**(2*alpha_Veg))/((Topt_Veg-Tmin_Veg)**(2*alpha_Veg)))[(t<Tmax_Veg) & (t>Tmin_Veg)]\n",
    "        ft1[np.where(ft1<0)]=0 \n",
    "\n",
    "        ft2=np.copy(t)\n",
    "        ft2[t>=Tmax_Rep]=0\n",
    "        ft2[t<=Tmin_Rep]=0        \n",
    "        ft2[(t<Tmax_Rep) & (t>Tmin_Rep)]=((2 * (t-Tmin_Rep)**alpha_Rep * (Topt_Rep-Tmin_Rep)**alpha_Rep - (t-Tmin_Rep)**(2*alpha_Rep))/((Topt_Rep-Tmin_Rep)**(2*alpha_Rep)))[(t<Tmax_Rep) & (t>Tmin_Rep)]\n",
    "        ft2[np.where(ft2<0)]=0 \n",
    "\n",
    "        c=dayl\n",
    "        fp1=np.copy(c)\n",
    "        fp1[c>=P_critical_Veg]=0\n",
    "        fp1[c<=P_optimum_Veg]=1        \n",
    "        fp1[(c<P_critical_Veg) & (c>P_optimum_Veg)]=((((c-P_optimum_Veg)/3 + 1)*((P_critical_Veg-c)/(P_critical_Veg-P_optimum_Veg))**((P_critical_Veg-P_optimum_Veg)/3))**alpha_photo_Veg)[(c<P_critical_Veg) & (c>P_optimum_Veg)]\n",
    "        fp1[np.where(fp1<0)]=0    \n",
    "\n",
    "        fp2=np.copy(c)\n",
    "        fp2[c>=P_critical_Rep]=0\n",
    "        fp2[c<=P_optimum_Rep]=1      \n",
    "        fp2[(c<P_critical_Rep) & (c>P_optimum_Rep)]=((((c-P_optimum_Rep)/3 + 1)*((P_critical_Rep-c)/(P_critical_Rep-P_optimum_Rep))**((P_critical_Rep-P_optimum_Rep)/3))**alpha_photo_Rep)[(c<P_critical_Rep) & (c>P_optimum_Rep)]\n",
    "        fp2[np.where(fp2<0)]=0  \n",
    "\n",
    "        fpt1=ft1*fp1\n",
    "        fpt2=ft2*fp2\n",
    "\n",
    "        src=rasterio.open(tmin_path)\n",
    "        profile=src.profile\n",
    "        profile.update(count=fpt1.shape[0])\n",
    "\n",
    "        with rasterio.open(outfile_Veg, 'w', **profile) as dst:\n",
    "            for i in range(fpt1.shape[0]):\n",
    "                dst.write(fpt1[i,:,:].astype(rasterio.float32), i+1)\n",
    "        \n",
    "        with rasterio.open(outfile_Rep, 'w', **profile) as dst:\n",
    "            for i in range(fpt2.shape[0]):\n",
    "                dst.write(fpt2[i,:,:].astype(rasterio.float32), i+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the APTT rasters for one year\n",
    "aptt_veg_path = os.path.join(output_aptt_path, 'APTT_winterwheat_vegetative_phase_'+str(end_aptt_generation_year-1)+'.tif')\n",
    "aptt_rep_path = os.path.join(output_aptt_path, 'APTT_winterwheat_reproductive_phase_'+str(end_aptt_generation_year-1)+'.tif')\n",
    "\n",
    "with rasterio.open(aptt_veg_path) as src:\n",
    "    aptt_veg = src.read()\n",
    "    aptt_veg_meta = src.profile\n",
    "\n",
    "with rasterio.open(aptt_rep_path) as src:\n",
    "    aptt_rep = src.read()\n",
    "    aptt_rep_meta = src.profile\n",
    "\n",
    "print(aptt_veg.shape)\n",
    "print(aptt_rep.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MAIN FLOW : DOUBLE LOGISTIC CURVE FITTING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>For each year, perform:</b>\n",
    "- <b>NDVI Two peak fitting</b>\n",
    "It can be observed that the NDVI values have two peaks. The first peak is the vegetative growth phase and the second peak is the reproductive growth phase. The double logistic curve is a good fit for this data. To determine the parameters for the double logistic curve, we will use the `scipy.optimize.least_squares` function. \n",
    "\n",
    "- Get Dividing Index\n",
    "- Plot the fitted curve with the actual data and the dividing index\n",
    "\n",
    "- <b>Individiual Double Logistic Curve Fitting</b>\n",
    "Split the ndvi and doy into two parts: vegetative and reproductive using the dividing index. Perform least square optimization to fit the double logistic curve to this data individually. This will give us the parameters for the double logistic curve for the vegetative and reproductive growth phases.\n",
    "- <b>Phenological Features Estimation</b>\n",
    "Use the fitted curves to estimate the phenological features. The phenological features are:\n",
    "    - Vegetative Active Greenup\n",
    "    - Vegetative End of Senescence\n",
    "    - Reproductive Active Greenup\n",
    "    - Reproductive End of Senescence\n",
    "- Add the necessary values to global variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform Double Logistic Curve Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndvis_discrete, ndvis, ndvis_diff1, ndvis_diff2, ndvis_diff3 = [], [], [], [], []\n",
    "doys_discrete, doys, doys_diff1, doys_diff2, doys_diff3 = [], [], [], [], []\n",
    "\n",
    "vegetative_greenups, reproductive_greenups, reproductive_senescense = [], [], []\n",
    "\n",
    "for year in range(ndvi_start_year,ndvi_end_year):\n",
    "    ndvi,doy = get_data(year)\n",
    "    # fitted_two_peak_ndvi, doy_cont = fit_two_peak_ndvi(ndvi, doy)\n",
    "    # dividing_value = get_dividing_index(fitted_two_peak_ndvi)\n",
    "    dividing_value = 130\n",
    "\n",
    "    # Get the doy index whose value is closest to the dividing value\n",
    "    dividing_index = (np.abs(doy - dividing_value)).argmin()\n",
    "\n",
    "    vegetative_ndvi,vegetative_doy = fit_ndvi(ndvi[:dividing_index], doy[:dividing_index],'vegetative',doy[dividing_index])\n",
    "    reproductive_ndvi,reproductive_doy = fit_ndvi(ndvi[dividing_index:], doy[dividing_index:], 'reproductive', 365)\n",
    "\n",
    "    values = get_phenological_doy(vegetative_ndvi,reproductive_ndvi)\n",
    "\n",
    "    ndvis_discrete += list(ndvi)\n",
    "    doys_discrete += list(doy + (year-ndvi_start_year)*365)\n",
    "\n",
    "    ndvis += list(vegetative_ndvi) + list(reproductive_ndvi)\n",
    "    doys += [d+(year-ndvi_start_year)*365 for d in list(vegetative_doy)] + [d+(year-ndvi_start_year)*365 for d in list(reproductive_doy)]\n",
    "\n",
    "    \n",
    "    ndvis_diff1 += list(values['vegetative_ndvi_diff1']) + list(values['reproductive_ndvi_diff1'])\n",
    "    doys_diff1 += [d+(year-ndvi_start_year)*365 for d in list(vegetative_doy[1:])] + [d+(year-ndvi_start_year)*365 for d in list(reproductive_doy[1:])]\n",
    "\n",
    "    ndvis_diff2 += list(values['vegetative_ndvi_diff2']) + list(values['reproductive_ndvi_diff2'])\n",
    "    doys_diff2 += [d+(year-ndvi_start_year)*365 for d in list(vegetative_doy[2:])] + [d+(year-ndvi_start_year)*365 for d in list(reproductive_doy[2:])]\n",
    "\n",
    "    ndvis_diff3 += list(values['vegetative_ndvi_diff3']) + list(values['reproductive_ndvi_diff3'])\n",
    "    doys_diff3 += [d+(year-ndvi_start_year)*365 for d in list(vegetative_doy[3:])] + [d+(year-ndvi_start_year)*365 for d in list(reproductive_doy[3:])]\n",
    "\n",
    "    vegetative_greenups.append(values['vegetative_greenup']+(year-ndvi_start_year)*365)\n",
    "    reproductive_greenups.append(values['reproductive_greenup']+(year-ndvi_start_year)*365 + doy[dividing_index])\n",
    "    reproductive_senescense.append(values['reproductive_senescense']+(year-ndvi_start_year)*365 + doy[dividing_index])\n",
    "\n",
    "    plt.figure(figsize=(10,2))\n",
    "    plt.plot(doy,ndvi)\n",
    "    plt.plot(vegetative_doy, vegetative_ndvi)\n",
    "    plt.plot(reproductive_doy, reproductive_ndvi)\n",
    "    plt.plot(doy[dividing_index], ndvi[dividing_index],'--rx')\n",
    "    plt.yticks([])\n",
    "    plt.title(str(year)+ ' to '+str(year+1))\n",
    "\n",
    "    plt.axvline(doys.index(values['vegetative_greenup']), color='green', linestyle='--', alpha=0.5)\n",
    "    plt.axvline(doys.index(values['reproductive_greenup'] + doy[dividing_index]), color='green', linestyle='--', alpha=0.5)\n",
    "    plt.axvline(doys.index(values['reproductive_senescense'] + doy[dividing_index]), color='red', linestyle='--', alpha=0.5)\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "print('Vegetative greenup: ', vegetative_greenups)\n",
    "print('Reproductive greenup: ', reproductive_greenups)\n",
    "print('Reproductive senescense: ', reproductive_senescense)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtain USDA state phenology data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "usda_df = pd.read_csv(os.path.join(usda_path, 'Kansas_state_phenological_dates.csv'))\n",
    "print(usda_df)\n",
    "\n",
    "crop_emergence_dates, joint_dates, heading_dates, turning_dates, ripening_dates, harvesting_dates = [], [], [], [], [], []\n",
    "for year in range(ndvi_start_year,ndvi_end_year):\n",
    "    df = usda_df[usda_df.year == year-1]\n",
    "    crop_emergence_dates.append(df['Crop emergence'].iloc[0] + (year-ndvi_start_year)*365 + (0 - 249))\n",
    "    joint_dates.append(df['Joint'].iloc[0] + (year-ndvi_start_year)*365 + (365-249) )\n",
    "    heading_dates.append(df['Heading'].iloc[0] + (year-ndvi_start_year)*365 + (365-249) )\n",
    "    turning_dates.append(df['Turning'].iloc[0] + (year-ndvi_start_year)*365 + (365-249) )\n",
    "    ripening_dates.append(df['Ripening'].iloc[0] + (year-ndvi_start_year)*365 + (365-249) )\n",
    "    harvesting_dates.append(df['Harvesting'].iloc[0] + (year-ndvi_start_year)*365 + (365-249) )\n",
    "\n",
    "print('Crop emergence dates: ', crop_emergence_dates)\n",
    "print('Joint dates: ', joint_dates)\n",
    "print('Heading dates: ', heading_dates)\n",
    "print('Turning dates: ', turning_dates)\n",
    "print('Ripening dates: ', ripening_dates)\n",
    "print('Harvesting dates: ', harvesting_dates)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zip_data():\n",
    "    return zip(\n",
    "        vegetative_greenups, reproductive_greenups, reproductive_senescense, \n",
    "        crop_emergence_dates, joint_dates, heading_dates, turning_dates, ripening_dates, harvesting_dates\n",
    "    )\n",
    "\n",
    "plot_ndvi(\n",
    "    doys, ndvis, \n",
    "    'NDVI Curve', \n",
    "    zip_data(),\n",
    "    (doys_discrete,ndvis_discrete)\n",
    "    # None\n",
    ")\n",
    "\n",
    "plot_ndvi(\n",
    "    doys_diff1, ndvis_diff1, \n",
    "    'First differential', \n",
    "    zip_data(),\n",
    "    None\n",
    ")\n",
    "\n",
    "# plot_ndvi(\n",
    "#     doys_diff2, ndvis_diff2, \n",
    "#     'Second differential', \n",
    "#     get_data()\n",
    "# )\n",
    "\n",
    "# plot_ndvi(\n",
    "#     doys_diff3, ndvis_diff3, \n",
    "#     'Third differential', \n",
    "#     zip_data(),\n",
    "#     None\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MAIN FLOW : Estimate Average APTT values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, year in tqdm(enumerate(range(aptt_start_year,aptt_end_year+1))):\n",
    "    aptt_veg_path = os.path.join(output_aptt_path, 'APTT_winterwheat_vegetative_phase_'+str(year)+'.tif')\n",
    "    aptt_rep_path = os.path.join(output_aptt_path, 'APTT_winterwheat_reproductive_phase_'+str(year)+'.tif')\n",
    "\n",
    "    raster1=rasterio.open(aptt_veg_path)\n",
    "    aptt1=raster1.read()\n",
    "    raster2=rasterio.open(aptt_rep_path)\n",
    "    aptt2=raster2.read()\n",
    "    \n",
    "    emergence_to_first_greenup = np.sum(aptt1[(181-273+crop_emergence_dates[i]):(181-273+vegetative_greenups[i]+1)], 0)\n",
    "    emergence_to_first_greenup_value = np.true_divide(emergence_to_first_greenup.sum(),(emergence_to_first_greenup!=0).sum())\n",
    "    \n",
    "    # doy 180 corresponds to index 179 of aptt2\n",
    "    joint_to_second_greenup = np.sum(aptt2[int(reproductive_greenups[i]-1):joint_dates[i]], 0)\n",
    "    joint_to_second_greenup_value = np.true_divide(joint_to_second_greenup.sum(),(joint_to_second_greenup!=0).sum())\n",
    "    \n",
    "    ripening_to_end_of_senescence = np.sum(aptt2[int(reproductive_senescense[i]-1):ripening_dates[i]], 0)\n",
    "    ripening_to_end_of_senescence_value = np.true_divide(ripening_to_end_of_senescence.sum(),(ripening_to_end_of_senescence!=0).sum())\n",
    "\n",
    "    print(str(year)+'-'+str(year+1)+' growing season:')\n",
    "    print('Emergence->first greenup: '+str(emergence_to_first_greenup_value))\n",
    "    print('second_greenup->joint: '+str(joint_to_second_greenup_value))\n",
    "    print('end of senescence->ripening: '+str(ripening_to_end_of_senescence_value))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('torch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "ac0de59e41daaff3652b5e35e9c975324a21be3dd4348ffe44afaedd082b8702"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
